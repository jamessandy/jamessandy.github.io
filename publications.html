<!DOCTYPE html>
<html>
  <head>
    <title>Jammie's Projects</title>
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link
      href="https://fonts.googleapis.com/css2?family=Overpass+Mono:wght@300;400;600;700&display=swap"
      rel="stylesheet"
    />
    <link
      rel="stylesheet"
      href="https://use.fontawesome.com/releases/v5.0.7/css/all.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
  </head>

  <body>
    <header class="site-header">
      <nav class="nav">
        <div class="container flex-wrap">
          <h1 class="logo">
            <a href="https://stevenkolawole.github.io/">James Sandy</a>
          </h1>
          <ul class="navbar">
            <li><a href="index.html">About</a></li>
            <li><a href="publications.html" class="active">Projects</a></li>
            <li><a href="blog.html">Blog</a></li>
            <li><a href="assets/Steven_Kolawole_CV.pdf" target="_blank">CV</a></li>
          </ul>
        </div>
      </nav>
    </header>

    <div class="page container">
      <h1 class="header-name">Projects</h1>
      
      <div class="publications-intro" style="text-align: justify">
        <p>My research explores efficiency problems in ML systems, focusing on making AI more accessible. 
        The work spans three main areas: developing efficient inference methods, addressing resource constraints 
        in multilingual settings, and building practical applications for social impact.</p>
      </div>

      <!-- ML research  -->
      <div class="publication-category">
        <h2 class="category-title">ML Research Related</h2>
        
        <div class="publication-item">
          <div class="pub-title">
            <a href="https://jammiesandy.substack.com/p/an-implementation-of-sparse-autoencoders" target="_blank">Paper Implementation: An implementation of Sparse Autoencoders to find highly interpretable features in GPT-2</a>
          </div>
          <div class="pub-authors"> <span class="author-highlight">James Sandy</span> </div>
          <div class="pub-venue">Mechanistic Interpretation</div>
        </div>
      

      <!-- AI projects -->
      <div class="publication-category">
        <h2 class="category-title">AI Projects</h2>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://huggingface.co/Jammies-io/livestockmodel-llama" target="_blank">Fine-tuned Llama 3.1 for Livestock guidance for rural farmers in Africa</a>
          </div>
          <div class="pub-authors"> <span class="author-highlight">James Sandy</span>*</div>
          <div class="pub-venue">HuggingFace</div>
          <div class="pub-description">
            I fine-tuned the Llama model on publications from the Nigerian Livestock Research Journal 
            and deployed it to users via WhatsApp.
          </div>
        </div>


      <!-- Data Projects -->
      <div class="publication-category">
        <h2 class="category-title">Data Projects</h2>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2305.19365" target="_blank">Vision Transformers for Mobile Applications: A Short Survey</a>
          </div>
          <div class="pub-authors">Nahid Alam*, <span class="author-highlight">Steven Kolawole</span>*, Simardeep Sethi*, Nishant Bansali, Karina Nguyen</div>
          <div class="pub-venue">arXiv preprint, 2023</div>
          <div class="pub-description">
            A comprehensive survey examining how Vision Transformers can be optimized for mobile deployment, 
            analyzing architecture modifications and efficiency techniques for resource-constrained environments.
          </div>
        </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://www.ijcai.org/proceedings/2022/0855.pdf" target="_blank">Sign-to-Speech Model for Sign Language Understanding: A Case Study of Nigerian Sign Language</a>
          </div>
          <div class="pub-authors"><span class="author-highlight">Steven Kolawole</span>, Opeyemi Osakuade, Nayan Saxena, Babatunde Kazeem Olorisade</div>
          <div class="pub-venue">IJCAI 2022 (AI for Social Good Track)</div>
          <div class="pub-description">
            Develops a sign-to-speech system for Nigerian Sign Language to bridge communication gaps. 
            This work earned the national AI Champion award from the Nigeria Computer Society, demonstrating practical AI for social impact.
          </div>
        </div>
      </div>

      <!-- External Links -->
      <div class="external-links">
        <h2 class="category-title">External Profiles</h2>
        <div class="external-link-list">
          <a href="https://scholar.google.com/citations?user=cekASD4AAAAJ&hl=en" target="_blank" class="external-link">
            <i class="ai ai-google-scholar"></i> Google Scholar Profile
          </a>
          <a href="https://openreview.net/profile?id=~Steven_Kolawole1" target="_blank" class="external-link">
            <i class="fas fa-file-alt"></i> OpenReview Profile
          </a>
          <a href="https://arxiv.org/search/?query=Kolawole%2C+Steven&searchtype=author" target="_blank" class="external-link">
            <i class="fas fa-archive"></i> arXiv Papers
          </a>
        </div>
      </div>

      <div class="publications-note">
        <p><small>* denotes equal contribution</small></p>
        <p><small>This list includes peer-reviewed publications, workshop papers, and preprints. 
        For the most up-to-date list with citation counts, please visit my Google Scholar profile.</small></p>
      </div>

    </div>
  </body>
</html>
